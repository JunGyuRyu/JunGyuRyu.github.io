[1pt=0.3527mm]
제목 및 저자: 71~85pt=25~30mm
각 장의 제목: 43~56pt=15~20mm
발표내용: 20~28pt=7~10mm

보드: 180x100cm

제목,저자,소속: 세로 20cm

1. background
5.6
90

2. method
6.4 6.4 6.4 6.4 6.4
5.2

----------------------------
Spiking neural networks (SNNs)는 생물학적 신경망에서 영감을 받은 인공 신경망의 한 종류이고, 생물학적 신경망의 작동 방식을 모방하여 시간에 따른 활성화 패턴을 사용하여 정보를 처리한다. 이러한 특성으로 인해 SNN은 이벤트 기반 처리가 가능하여 저전력 동작이 가능하다는 장점이 있다. 기존 deep neural networks (DNNs) 아키텍처의 설계는 인간의 지식과 경험에 의해 설계되었다. 보다 높은 성능의 DNN 구조를 위해 neural architecture search (NAS)와 같은 구조 탐색 기술이 제안되었고, 높은 성능의 deep SNN 구조를 탐색하기 위해 NAS 기술을 활용하는 연구들이 발표되고 있다. 그러나 기존의 연구들은 여러 탐색 알고리즘에 따른 NAS 성능에 대한 분석을 제시하고 있지 않다. 따라서 본 논문에서는 3가지 탐색 알고리즘 (Random, Greedy, Bayesian)에 대해 DNN 및 deep SNN의 구조 탐색 성능을 분석해 보았다. CIFAR-10 데이터셋에서 검증 정확도를 측정하고,  이를 통해 각 알고리즘의 성능 차이를 비교 분석하여, SNN 모델의 자동 최적화에 대한 이해를 높이고자 한다.
----------------------------

----------------------------
각 Neuron이 스파이크를 전송하는 예시를 그린 그림이다. post-neuron의 막전위는 pre-neuron 으로부터 스파이크를 받을 때 특정 값만큼 증가하고, 시간이 지남에 따라 서서히 줄어든다. post-Neuron에 들어오게 되면, 막전위가 임계 값을 넘어 출력 스파이크를 발생시키고, 그와 동시에 post-neuron 막전위의 값은 초기화된다.

NAS는 일반적으로 구성 요소를 정의하고, 정의된 탐색 공간에서 최적의 후보 아키텍처를 찾는다. 마지막으로 아키텍처의 성능 평가를 기준 삼아 탐색 알고리즘에 따라 새로운 아키텍처를 찾는다. 최대한 넓은 탐색 공간에서 가장 효율적으로 최적의 아키텍처를 탐색하는 것이 뛰어난 알고리즘이라 할 수 있다. 
----------------------------

----------------------------
검증 정확도(Validation Accuracy)를 기준으로 DNN에서 가장 성능이 좋은 알고리즘은 90.54%인 Greedy였고, SNN의 모든 조건에서 Bayesian 알고리즘의 검증 정확도가 다른 알고리즘들 보다 높았다. SNN의 여러 구성 중 성능이 가장 뛰어난 것은 LIF, Soft를 사용해 검증 정확도가 91.73%로 나타난 Bayesian 알고리즘이다. 

뉴런 모델을 기준으로 비교해보면 Soft에서는 약 2~3% 차이로 LIF의 검증 정확도가 IF보다 높았으며 Hard에서도 비록 적은 차이지만 LIF가 더 높았다. Reset 방법을 기준으로 비교해보면 LIF에서는 Soft의 검증 정확도가 약 6~8%, IF에서도 Soft가 약 4~5% 더 높다는 것을 알 수 있다. 스파이크 수 측면에서 봤을 때, SNN에서 가장 스파이크 수가 적은 Random의 검증 정확도는 86.08%로, 이는 비슷한 스파이크 수를 가진 LIF, Hard를 사용한 Greedy에 비해 훨씬 높은 검증 정확도를 보여준다. 또한 스파이크 수가 가장 높은 IF, Hard를 사용한 Bayesian은, IF, Soft를 사용한 Bayesian과 스파이크 수가 비슷하지만 정확도는 6% 가량 차이가 난다. 

본 실험을 통해 뉴런 모델, reset 방법, 모델의 아키텍처 등 주어진 조건에 따라 다른 효율이 나올 수 있다는 것을 확인할 수 있다. 결과적으로, 세 가지 알고리즘 중에서는 Bayesian, 뉴런 모델은 LIF, reset 방법은 Soft가 더 좋은 성능을 보였음을 알 수 있다.
----------------------------






